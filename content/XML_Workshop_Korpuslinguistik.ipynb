{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60298061",
   "metadata": {},
   "source": [
    "\n",
    "# XML f√ºr die Korpuslinguistik ‚Äî Workshop (90 Minuten)\n",
    "\n",
    "**Dozent**: Phillip B. Str√∂bel (UZH)  \n",
    "**Ziele**: In 90 Minuten weisst du, ‚Ä¶  \n",
    "- was XML ist und warum es sich in der Korpuslinguistik bew√§hrt,  \n",
    "- was Header/Body bedeutet (z.‚ÄØB. TEI),  \n",
    "- wie Tags/Attribute/Hierarchien funktionieren,  \n",
    "- was der Unterschied zwischen flachem und tiefem XML ist,  \n",
    "- welche Python-Bibliotheken sich f√ºr XML eignen und wie man einfache Analysen macht.\n",
    "\n",
    "**Material**: Dieses Notebook findest du unter https://pstroe.github.io/xml-workshop-zukoko-2025/lab/index.html. Die Daten im Ordner `data/`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66866865",
   "metadata": {},
   "source": [
    "\n",
    "## 0) Setup\n",
    "Wir verwenden prim√§r die Standardbibliothek `xml.etree.ElementTree` (kurz: `ET`). Falls verf√ºgbar, nutzen wir optional `lxml` f√ºr XPath.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f39d9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports & Feature-Flags\n",
    "import os\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Optional: lxml (f√ºr volle XPath-Unterst√ºtzung)\n",
    "try:\n",
    "    import lxml.etree as LET\n",
    "    USING_LXML = True\n",
    "except Exception as e:\n",
    "    USING_LXML = False\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "print(\"USING_LXML =\", USING_LXML)\n",
    "print(\"DATA_DIR =\", DATA_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b7fe1a",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Erste Beispiele: TEI und Gespr√§chs-Korpus\n",
    "Wir schauen uns zwei Dateien an:\n",
    "- `tei_sample.xml` (Header/Body-Struktur)  \n",
    "- `corpus_small.xml` (Dialog mit `<u>`, `<s>`, `<w>` und `<pc>`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b541115",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Datei laden und Root inspizieren (ElementTree)\n",
    "tei_path = DATA_DIR / \"tei_sample.xml\"\n",
    "tree = ET.parse(tei_path)\n",
    "root = tree.getroot()\n",
    "print(\"Root-Tag (mit Namespace):\", root.tag)\n",
    "print(\"Kinder:\", [child.tag for child in list(root)[:3]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d259ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dialog-Korpus laden und erste Tokens ausgeben\n",
    "corpus_path = DATA_DIR / \"corpus_small.xml\"\n",
    "ctree = ET.parse(corpus_path)\n",
    "croot = ctree.getroot()\n",
    "\n",
    "for u in croot.findall(\".//u\"):\n",
    "    speaker = u.attrib.get(\"who\")\n",
    "    words = [ (w.text or \"\") for w in u.findall(\".//w\") ]\n",
    "    print(speaker, \":\", \" \".join(words))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ffec2f",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Tags, Attribute, Hierarchie kurz & b√ºndig\n",
    "- **Elemente** (Tags): `<w>Gehe</w>`  \n",
    "- **Attribute**: `<w lemma=\"gehen\" pos=\"VVFIN\">Gehe</w>`  \n",
    "- **Hierarchie**: `<u>` enth√§lt `<s>`, `<s>` enth√§lt `<w>` und `<pc>`.\n",
    "\n",
    "üëâ **Mini-Aufgabe:** Hole alle Wortformen (`<w>`) von Sprecher `#A` und gib sie als Liste aus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfe73ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# L√∂sungsvorschlag\n",
    "words_a = []\n",
    "for u in croot.findall(\".//u\"):\n",
    "    if u.attrib.get(\"who\") == \"#A\":\n",
    "        words_a.extend([ (w.text or \"\") for w in u.findall(\".//w\") ])\n",
    "\n",
    "words_a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c8e488",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Flaches vs. tiefes XML\n",
    "- **Flach**: Informationen als Attribute in h√∂herer Ebene (z.‚ÄØB. alle Tokens als String-Attribut)\n",
    "- **Tief**: Explizite Verschachtelung mit Unterelementen\n",
    "\n",
    "Beispieldateien:\n",
    "- `corpus_flat.xml` (flach)\n",
    "- `corpus_small.xml` (tief)\n",
    "\n",
    "üëâ **Aufgabe:** Parse `corpus_flat.xml` und splitte die Tokens pro Sprecher.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc62a3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# L√∂sungsvorschlag\n",
    "flat_path = DATA_DIR / \"corpus_flat.xml\"\n",
    "ftree = ET.parse(flat_path)\n",
    "froot = ftree.getroot()\n",
    "\n",
    "for u in froot.findall(\".//u\"):\n",
    "    speaker = u.attrib.get(\"who\")\n",
    "    toks = (u.attrib.get(\"tokens\") or \"\").split(\"|\")\n",
    "    toks = [t.strip() for t in toks if t.strip()]\n",
    "    print(speaker, \":\", toks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42027557",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Token-Frequenzen, Lemmata und POS\n",
    "Wir extrahieren Tokens (`<w>`) und z√§hlen Frequenzen. Dann fassen wir nach Lemma und POS zusammen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650ad92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "def iter_tokens(root):\n",
    "    for w in root.findall(\".//w\"):\n",
    "        yield (w.text or \"\"), w.attrib.get(\"lemma\"), w.attrib.get(\"pos\")\n",
    "\n",
    "rows = [(form, lemma, pos) for form, lemma, pos in iter_tokens(croot)]\n",
    "df = pd.DataFrame(rows, columns=[\"form\", \"lemma\", \"pos\"])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122097fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# H√§ufigkeiten der Wortformen\n",
    "form_counts = df[\"form\"].value_counts().reset_index()\n",
    "form_counts.columns = [\"form\", \"freq\"]\n",
    "form_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42159191",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gruppierung nach Lemma und POS\n",
    "lemma_pos_counts = df.groupby([\"lemma\", \"pos\"]).size().reset_index(name=\"freq\")\n",
    "lemma_pos_counts.sort_values(\"freq\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b67c45",
   "metadata": {},
   "source": [
    "\n",
    "## 5) (Optional) Visualisierung der Top-Token\n",
    "Ein einfacher Balkenplot der h√§ufigsten Formen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a0adbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "topn = 10\n",
    "top_forms = form_counts.head(topn)\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(top_forms[\"form\"], top_forms[\"freq\"])  # keine Farben explizit setzen\n",
    "plt.title(f\"Top {topn} Wortformen\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00094de",
   "metadata": {},
   "source": [
    "\n",
    "## 6) XPath (mit lxml, falls installiert)\n",
    "Mit `lxml` k√∂nnen wir volle XPath-Queries ausf√ºhren. Beispiel: alle finiten Verben (`pos=\"VVFIN\"`) von Sprecher `#A`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463a69cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if USING_LXML:\n",
    "    # lxml-Parsing\n",
    "    ltree = LET.parse(str(corpus_path))\n",
    "    lroot = ltree.getroot()\n",
    "    # XPath-Query\n",
    "    nodes = lroot.xpath(\".//u[@who='#A']//w[@pos='VVFIN']\")\n",
    "    [n.text for n in nodes]\n",
    "else:\n",
    "    print(\"lxml ist nicht verf√ºgbar. √úberspringe XPath-Beispiel.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7b6fab",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Schreiben und Modifizieren von XML\n",
    "Wir f√ºgen eine einfache Normalisierung hinzu: Attribut `norm` f√ºr Tokens in Grossbuchstaben (`text.upper()`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c200920",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Kopie laden, norm hinzuf√ºgen und speichern\n",
    "tree2 = ET.parse(corpus_path)\n",
    "root2 = tree2.getroot()\n",
    "\n",
    "for w in root2.findall(\".//w\"):\n",
    "    if w.text:\n",
    "        w.set(\"norm\", w.text.upper())\n",
    "\n",
    "out_path = DATA_DIR / \"corpus_annotated.xml\"\n",
    "tree2.write(out_path, encoding=\"utf-8\", xml_declaration=True)\n",
    "print(\"Gespeichert:\", out_path.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919d4523",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Well-formedness & Fehlersuche\n",
    "Wir versuchen, `broken.xml` zu parsen und fangen den Fehler ab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a303ddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "broken_path = DATA_DIR / \"broken.xml\"\n",
    "try:\n",
    "    ET.parse(broken_path)\n",
    "    print(\"Kein Fehler erkannt (unerwartet).\")\n",
    "except ET.ParseError as e:\n",
    "    print(\"ParseError:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd94aff",
   "metadata": {},
   "source": [
    "\n",
    "## 9) √úbungen\n",
    "**√úbung 1 (5‚Äì10 Min):**  \n",
    "Konvertiere `dialogue.txt` zu einfachem XML mit `<u who>`, `<s>`, `<w>`.  \n",
    "Tipp: Splitte Zeilen nach `\":\"` (Sprecher) und whitespace (Tokens).\n",
    "\n",
    "**√úbung 2 (10 Min):**  \n",
    "Berechne f√ºr `corpus_small.xml` die **Type-Token-Ratio (TTR)** pro Sprecher.\n",
    "\n",
    "**√úbung 3 (10‚Äì15 Min):**  \n",
    "Erzeuge **Bigrams** (Folgepaare) der Wortformen pro Sprecher und z√§hle die h√§ufigsten.\n",
    "\n",
    "**Bonus (falls Zeit):**  \n",
    "- F√ºge eine neue Annotation `sentiment=\"pos/neg/neu\"` zu allen Tokens hinzu (dummy: pos f√ºr A, neu f√ºr B).  \n",
    "- Exportiere eine Token-Tabelle als CSV (Form, Lemma, POS, Sprecher).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f2d7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Starte hier mit √úbung 1:\n",
    "# 1) Lade dialogue.txt, 2) parse die Zeilen, 3) baue ein XML-Baumobjekt, 4) speichere als dialogue.xml\n",
    "\n",
    "from xml.etree.ElementTree import Element, SubElement, ElementTree\n",
    "\n",
    "dlg_in = (DATA_DIR / \"dialogue.txt\").read_text(encoding=\"utf-8\").splitlines()\n",
    "\n",
    "root = Element(\"corpus\", {\"xml:lang\":\"de\"})\n",
    "sid = 1\n",
    "for line in dlg_in:\n",
    "    if \":\" not in line:\n",
    "        continue\n",
    "    speaker, text = line.split(\":\", 1)\n",
    "    speaker = speaker.strip().replace(\"Speaker \", \"#\")\n",
    "    u = SubElement(root, \"u\", {\"who\": speaker})\n",
    "    s = SubElement(u, \"s\", {\"n\": str(sid)})\n",
    "    sid += 1\n",
    "    # sehr simple Tokenisierung\n",
    "    for tok in text.strip().split():\n",
    "        if tok in [\".\", \",\", \"!\", \"?\", \";\", \":\"]:\n",
    "            pc = SubElement(s, \"pc\")\n",
    "            pc.text = tok\n",
    "        else:\n",
    "            w = SubElement(s, \"w\")\n",
    "            w.text = tok\n",
    "\n",
    "out_xml = DATA_DIR / \"dialogue.xml\"\n",
    "ElementTree(root).write(out_xml, encoding=\"utf-8\", xml_declaration=True)\n",
    "print(\"dialogue.xml gespeichert nach:\", out_xml.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203ebaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# √úbung 2: TTR pro Sprecher (L√∂sungsvorschlag)\n",
    "\n",
    "def ttr_for_speaker(root, who):\n",
    "    tokens = [ (w.text or \"\") for w in root.findall(f\".//u[@who='{who}']//w\") ]\n",
    "    types = set(tokens)\n",
    "    return len(types) / max(1, len(tokens))\n",
    "\n",
    "root_dialogue = ET.parse(DATA_DIR / \"dialogue.xml\").getroot()\n",
    "speakers = sorted({u.attrib.get(\"who\") for u in root_dialogue.findall(\".//u\")})\n",
    "\n",
    "for spk in speakers:\n",
    "    print(spk, \"TTR =\", round(ttr_for_speaker(root_dialogue, spk), 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d504ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# √úbung 3: Bigrams z√§hlen (L√∂sungsvorschlag)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def bigrams(seq):\n",
    "    for i in range(len(seq)-1):\n",
    "        yield (seq[i], seq[i+1])\n",
    "\n",
    "def speaker_bigrams(root, who):\n",
    "    toks = [ (w.text or \"\") for w in root.findall(f\".//u[@who='{who}']//w\") ]\n",
    "    return Counter(bigrams(toks))\n",
    "\n",
    "for spk in speakers:\n",
    "    bg = speaker_bigrams(root_dialogue, spk).most_common(10)\n",
    "    print(\"\\n\", spk, \"Top-10 Bigrams:\")\n",
    "    for (a, b), f in bg:\n",
    "        print(f\"{a} {b} -> {f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ae4d96",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Export: Token-Tabelle als CSV\n",
    "Wir schreiben eine Tokenliste (Form, Lemma, POS, Sprecher) aus `corpus_small.xml` als CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daf0df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows = []\n",
    "for u in croot.findall(\".//u\"):\n",
    "    spk = u.attrib.get(\"who\")\n",
    "    for w in u.findall(\".//w\"):\n",
    "        rows.append({\n",
    "            \"speaker\": spk,\n",
    "            \"form\": w.text or \"\",\n",
    "            \"lemma\": w.attrib.get(\"lemma\"),\n",
    "            \"pos\": w.attrib.get(\"pos\")\n",
    "        })\n",
    "\n",
    "df_tokens = pd.DataFrame(rows)\n",
    "csv_path = DATA_DIR / \"corpus_tokens.csv\"\n",
    "df_tokens.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "csv_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c1134b",
   "metadata": {},
   "source": [
    "\n",
    "## 11) Ausblick & Ressourcen\n",
    "- **Standards**: TEI, EpiDoc, ParlaMint  \n",
    "- **Validierung**: RELAX NG / Schematron (meist mit oXygen oder CI-Workflows)  \n",
    "- **Python**: `xml.etree.ElementTree` f√ºr Basics, `lxml` f√ºr XPath/XSLT\n",
    "- **Weiteres**: Export zu CoNLL/CSV, Alignments, UD, etc.\n",
    "\n",
    "Viel Erfolg beim Ausprobieren!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
